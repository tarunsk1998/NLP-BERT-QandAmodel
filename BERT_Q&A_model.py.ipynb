{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8914532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bbe2d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>When was the Vat formally opened?</td>\n",
       "      <td>It was formally established in 1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>what is the library for?</td>\n",
       "      <td>research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>for what subjects?</td>\n",
       "      <td>history, and law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>and?</td>\n",
       "      <td>philosophy, science and theology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>what was started in 2014?</td>\n",
       "      <td>a  project</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story  \\\n",
       "0  The Vatican Apostolic Library (), more commonl...   \n",
       "1  The Vatican Apostolic Library (), more commonl...   \n",
       "2  The Vatican Apostolic Library (), more commonl...   \n",
       "3  The Vatican Apostolic Library (), more commonl...   \n",
       "4  The Vatican Apostolic Library (), more commonl...   \n",
       "\n",
       "                            question                               answer  \n",
       "0  When was the Vat formally opened?  It was formally established in 1475  \n",
       "1           what is the library for?                             research  \n",
       "2                 for what subjects?                     history, and law  \n",
       "3                               and?     philosophy, science and theology  \n",
       "4          what was started in 2014?                           a  project  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coqa = pd.read_csv(\"coQA_data.csv\")\n",
    "coqa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f171fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 108647 entries, 0 to 108646\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   story     108647 non-null  object\n",
      " 1   question  108647 non-null  object\n",
      " 2   answer    108647 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "coqa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "13c43580",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f85a2072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Vatican Apostolic Library (), more commonly called the Vatican Library or simply the Vat, is the library of the Holy See, located in Vatican City. Formally established in 1475, although it is much older, it is one of the oldest libraries in the world and contains one of the most significant collections of historical texts. It has 75,000 codices from throughout history, as well as 1.1 million printed books, which include some 8,500 incunabula. \\n\\nThe Vatican Library is a research library for history, law, philosophy, science and theology. The Vatican Library is open to anyone who can document their qualifications and research needs. Photocopies for private study of pages from books published between 1801 and 1990 can be requested in person or by mail. \\n\\nIn March 2014, the Vatican Library began an initial four-year project of digitising its collection of manuscripts, to be made available online. \\n\\nThe Vatican Secret Archives were separated from the library at the beginning of the 17th century; they contain another 150,000 items. \\n\\nScholars have traditionally divided the history of the library into five periods, Pre-Lateran, Lateran, Avignon, Pre-Vatican and Vatican. \\n\\nThe Pre-Lateran period, comprising the initial days of the library, dated from the earliest days of the Church. Only a handful of volumes survive from this period, though some are very significant.'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_text = coqa[\"story\"][5]\n",
    "story_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "dea530f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how do scholars divide the library?\n",
      "into periods\n"
     ]
    }
   ],
   "source": [
    "question_text = coqa[\"question\"][5]\n",
    "print(question_text)\n",
    "answer_text = coqa[\"answer\"][5]\n",
    "print(answer_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ec0b6d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2129,  2079,  5784, 11443,  1996,  3075,  1029,   102,  1996,\n",
       "         12111, 11815,  3075,  1006,  1007,  1010,  2062,  4141,  2170,  1996,\n",
       "         12111,  3075,  2030,  3432,  1996, 12436,  2102,  1010,  2003,  1996,\n",
       "          3075,  1997,  1996,  4151,  2156,  1010,  2284,  1999, 12111,  2103,\n",
       "          1012,  6246,  2511,  1999, 16471,  2629,  1010,  2348,  2009,  2003,\n",
       "          2172,  3080,  1010,  2009,  2003,  2028,  1997,  1996,  4587,  8860,\n",
       "          1999,  1996,  2088,  1998,  3397,  2028,  1997,  1996,  2087,  3278,\n",
       "          6407,  1997,  3439,  6981,  1012,  2009,  2038,  4293,  1010,  2199,\n",
       "         19429, 23522,  2013,  2802,  2381,  1010,  2004,  2092,  2004,  1015,\n",
       "          1012,  1015,  2454,  6267,  2808,  1010,  2029,  2421,  2070,  1022,\n",
       "          1010,  3156,  4297,  9521, 28507,  1012,  1996, 12111,  3075,  2003,\n",
       "          1037,  2470,  3075,  2005,  2381,  1010,  2375,  1010,  4695,  1010,\n",
       "          2671,  1998,  8006,  1012,  1996, 12111,  3075,  2003,  2330,  2000,\n",
       "          3087,  2040,  2064,  6254,  2037, 15644,  1998,  2470,  3791,  1012,\n",
       "          6302,  3597, 13046,  2005,  2797,  2817,  1997,  5530,  2013,  2808,\n",
       "          2405,  2090, 12410,  1998,  2901,  2064,  2022,  7303,  1999,  2711,\n",
       "          2030,  2011,  5653,  1012,  1999,  2233,  2297,  1010,  1996, 12111,\n",
       "          3075,  2211,  2019,  3988,  2176,  1011,  2095,  2622,  1997, 15340,\n",
       "          9355,  2049,  3074,  1997, 10485,  1010,  2000,  2022,  2081,  2800,\n",
       "          3784,  1012,  1996, 12111,  3595,  8264,  2020,  5459,  2013,  1996,\n",
       "          3075,  2012,  1996,  2927,  1997,  1996,  5550,  2301,  1025,  2027,\n",
       "          5383,  2178,  5018,  1010,  2199,  5167,  1012,  5784,  2031,  6964,\n",
       "          4055,  1996,  2381,  1997,  1996,  3075,  2046,  2274,  6993,  1010,\n",
       "          3653,  1011,  2101,  2319,  1010,  2101,  2319,  1010, 20704, 24796,\n",
       "          1010,  3653,  1011, 12111,  1998, 12111,  1012,  1996,  3653,  1011,\n",
       "          2101,  2319,  2558,  1010,  9605,  1996,  3988,  2420,  1997,  1996,\n",
       "          3075,  1010,  6052,  2013,  1996,  5700,  2420,  1997,  1996,  2277,\n",
       "          1012,  2069,  1037,  9210,  1997,  6702,  5788,  2013,  2023,  2558,\n",
       "          1010,  2295,  2070,  2024,  2200,  3278,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer.encode_plus(question_text, story_text, add_special_tokens=True, return_tensors=\"pt\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ee3f2d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 2129,\n",
       " 2079,\n",
       " 5784,\n",
       " 11443,\n",
       " 1996,\n",
       " 3075,\n",
       " 1029,\n",
       " 102,\n",
       " 1996,\n",
       " 12111,\n",
       " 11815,\n",
       " 3075,\n",
       " 1006,\n",
       " 1007,\n",
       " 1010,\n",
       " 2062,\n",
       " 4141,\n",
       " 2170,\n",
       " 1996,\n",
       " 12111,\n",
       " 3075,\n",
       " 2030,\n",
       " 3432,\n",
       " 1996,\n",
       " 12436,\n",
       " 2102,\n",
       " 1010,\n",
       " 2003,\n",
       " 1996,\n",
       " 3075,\n",
       " 1997,\n",
       " 1996,\n",
       " 4151,\n",
       " 2156,\n",
       " 1010,\n",
       " 2284,\n",
       " 1999,\n",
       " 12111,\n",
       " 2103,\n",
       " 1012,\n",
       " 6246,\n",
       " 2511,\n",
       " 1999,\n",
       " 16471,\n",
       " 2629,\n",
       " 1010,\n",
       " 2348,\n",
       " 2009,\n",
       " 2003,\n",
       " 2172,\n",
       " 3080,\n",
       " 1010,\n",
       " 2009,\n",
       " 2003,\n",
       " 2028,\n",
       " 1997,\n",
       " 1996,\n",
       " 4587,\n",
       " 8860,\n",
       " 1999,\n",
       " 1996,\n",
       " 2088,\n",
       " 1998,\n",
       " 3397,\n",
       " 2028,\n",
       " 1997,\n",
       " 1996,\n",
       " 2087,\n",
       " 3278,\n",
       " 6407,\n",
       " 1997,\n",
       " 3439,\n",
       " 6981,\n",
       " 1012,\n",
       " 2009,\n",
       " 2038,\n",
       " 4293,\n",
       " 1010,\n",
       " 2199,\n",
       " 19429,\n",
       " 23522,\n",
       " 2013,\n",
       " 2802,\n",
       " 2381,\n",
       " 1010,\n",
       " 2004,\n",
       " 2092,\n",
       " 2004,\n",
       " 1015,\n",
       " 1012,\n",
       " 1015,\n",
       " 2454,\n",
       " 6267,\n",
       " 2808,\n",
       " 1010,\n",
       " 2029,\n",
       " 2421,\n",
       " 2070,\n",
       " 1022,\n",
       " 1010,\n",
       " 3156,\n",
       " 4297,\n",
       " 9521,\n",
       " 28507,\n",
       " 1012,\n",
       " 1996,\n",
       " 12111,\n",
       " 3075,\n",
       " 2003,\n",
       " 1037,\n",
       " 2470,\n",
       " 3075,\n",
       " 2005,\n",
       " 2381,\n",
       " 1010,\n",
       " 2375,\n",
       " 1010,\n",
       " 4695,\n",
       " 1010,\n",
       " 2671,\n",
       " 1998,\n",
       " 8006,\n",
       " 1012,\n",
       " 1996,\n",
       " 12111,\n",
       " 3075,\n",
       " 2003,\n",
       " 2330,\n",
       " 2000,\n",
       " 3087,\n",
       " 2040,\n",
       " 2064,\n",
       " 6254,\n",
       " 2037,\n",
       " 15644,\n",
       " 1998,\n",
       " 2470,\n",
       " 3791,\n",
       " 1012,\n",
       " 6302,\n",
       " 3597,\n",
       " 13046,\n",
       " 2005,\n",
       " 2797,\n",
       " 2817,\n",
       " 1997,\n",
       " 5530,\n",
       " 2013,\n",
       " 2808,\n",
       " 2405,\n",
       " 2090,\n",
       " 12410,\n",
       " 1998,\n",
       " 2901,\n",
       " 2064,\n",
       " 2022,\n",
       " 7303,\n",
       " 1999,\n",
       " 2711,\n",
       " 2030,\n",
       " 2011,\n",
       " 5653,\n",
       " 1012,\n",
       " 1999,\n",
       " 2233,\n",
       " 2297,\n",
       " 1010,\n",
       " 1996,\n",
       " 12111,\n",
       " 3075,\n",
       " 2211,\n",
       " 2019,\n",
       " 3988,\n",
       " 2176,\n",
       " 1011,\n",
       " 2095,\n",
       " 2622,\n",
       " 1997,\n",
       " 15340,\n",
       " 9355,\n",
       " 2049,\n",
       " 3074,\n",
       " 1997,\n",
       " 10485,\n",
       " 1010,\n",
       " 2000,\n",
       " 2022,\n",
       " 2081,\n",
       " 2800,\n",
       " 3784,\n",
       " 1012,\n",
       " 1996,\n",
       " 12111,\n",
       " 3595,\n",
       " 8264,\n",
       " 2020,\n",
       " 5459,\n",
       " 2013,\n",
       " 1996,\n",
       " 3075,\n",
       " 2012,\n",
       " 1996,\n",
       " 2927,\n",
       " 1997,\n",
       " 1996,\n",
       " 5550,\n",
       " 2301,\n",
       " 1025,\n",
       " 2027,\n",
       " 5383,\n",
       " 2178,\n",
       " 5018,\n",
       " 1010,\n",
       " 2199,\n",
       " 5167,\n",
       " 1012,\n",
       " 5784,\n",
       " 2031,\n",
       " 6964,\n",
       " 4055,\n",
       " 1996,\n",
       " 2381,\n",
       " 1997,\n",
       " 1996,\n",
       " 3075,\n",
       " 2046,\n",
       " 2274,\n",
       " 6993,\n",
       " 1010,\n",
       " 3653,\n",
       " 1011,\n",
       " 2101,\n",
       " 2319,\n",
       " 1010,\n",
       " 2101,\n",
       " 2319,\n",
       " 1010,\n",
       " 20704,\n",
       " 24796,\n",
       " 1010,\n",
       " 3653,\n",
       " 1011,\n",
       " 12111,\n",
       " 1998,\n",
       " 12111,\n",
       " 1012,\n",
       " 1996,\n",
       " 3653,\n",
       " 1011,\n",
       " 2101,\n",
       " 2319,\n",
       " 2558,\n",
       " 1010,\n",
       " 9605,\n",
       " 1996,\n",
       " 3988,\n",
       " 2420,\n",
       " 1997,\n",
       " 1996,\n",
       " 3075,\n",
       " 1010,\n",
       " 6052,\n",
       " 2013,\n",
       " 1996,\n",
       " 5700,\n",
       " 2420,\n",
       " 1997,\n",
       " 1996,\n",
       " 2277,\n",
       " 1012,\n",
       " 2069,\n",
       " 1037,\n",
       " 9210,\n",
       " 1997,\n",
       " 6702,\n",
       " 5788,\n",
       " 2013,\n",
       " 2023,\n",
       " 2558,\n",
       " 1010,\n",
       " 2295,\n",
       " 2070,\n",
       " 2024,\n",
       " 2200,\n",
       " 3278,\n",
       " 1012,\n",
       " 102]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "a59e78e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'how',\n",
       " 'do',\n",
       " 'scholars',\n",
       " 'divide',\n",
       " 'the',\n",
       " 'library',\n",
       " '?',\n",
       " '[SEP]',\n",
       " 'the',\n",
       " 'vatican',\n",
       " 'apostolic',\n",
       " 'library',\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " 'more',\n",
       " 'commonly',\n",
       " 'called',\n",
       " 'the',\n",
       " 'vatican',\n",
       " 'library',\n",
       " 'or',\n",
       " 'simply',\n",
       " 'the',\n",
       " 'va',\n",
       " '##t',\n",
       " ',',\n",
       " 'is',\n",
       " 'the',\n",
       " 'library',\n",
       " 'of',\n",
       " 'the',\n",
       " 'holy',\n",
       " 'see',\n",
       " ',',\n",
       " 'located',\n",
       " 'in',\n",
       " 'vatican',\n",
       " 'city',\n",
       " '.',\n",
       " 'formally',\n",
       " 'established',\n",
       " 'in',\n",
       " '147',\n",
       " '##5',\n",
       " ',',\n",
       " 'although',\n",
       " 'it',\n",
       " 'is',\n",
       " 'much',\n",
       " 'older',\n",
       " ',',\n",
       " 'it',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'oldest',\n",
       " 'libraries',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " 'and',\n",
       " 'contains',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'most',\n",
       " 'significant',\n",
       " 'collections',\n",
       " 'of',\n",
       " 'historical',\n",
       " 'texts',\n",
       " '.',\n",
       " 'it',\n",
       " 'has',\n",
       " '75',\n",
       " ',',\n",
       " '000',\n",
       " 'cod',\n",
       " '##ices',\n",
       " 'from',\n",
       " 'throughout',\n",
       " 'history',\n",
       " ',',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " '1',\n",
       " '.',\n",
       " '1',\n",
       " 'million',\n",
       " 'printed',\n",
       " 'books',\n",
       " ',',\n",
       " 'which',\n",
       " 'include',\n",
       " 'some',\n",
       " '8',\n",
       " ',',\n",
       " '500',\n",
       " 'inc',\n",
       " '##una',\n",
       " '##bula',\n",
       " '.',\n",
       " 'the',\n",
       " 'vatican',\n",
       " 'library',\n",
       " 'is',\n",
       " 'a',\n",
       " 'research',\n",
       " 'library',\n",
       " 'for',\n",
       " 'history',\n",
       " ',',\n",
       " 'law',\n",
       " ',',\n",
       " 'philosophy',\n",
       " ',',\n",
       " 'science',\n",
       " 'and',\n",
       " 'theology',\n",
       " '.',\n",
       " 'the',\n",
       " 'vatican',\n",
       " 'library',\n",
       " 'is',\n",
       " 'open',\n",
       " 'to',\n",
       " 'anyone',\n",
       " 'who',\n",
       " 'can',\n",
       " 'document',\n",
       " 'their',\n",
       " 'qualifications',\n",
       " 'and',\n",
       " 'research',\n",
       " 'needs',\n",
       " '.',\n",
       " 'photo',\n",
       " '##co',\n",
       " '##pies',\n",
       " 'for',\n",
       " 'private',\n",
       " 'study',\n",
       " 'of',\n",
       " 'pages',\n",
       " 'from',\n",
       " 'books',\n",
       " 'published',\n",
       " 'between',\n",
       " '1801',\n",
       " 'and',\n",
       " '1990',\n",
       " 'can',\n",
       " 'be',\n",
       " 'requested',\n",
       " 'in',\n",
       " 'person',\n",
       " 'or',\n",
       " 'by',\n",
       " 'mail',\n",
       " '.',\n",
       " 'in',\n",
       " 'march',\n",
       " '2014',\n",
       " ',',\n",
       " 'the',\n",
       " 'vatican',\n",
       " 'library',\n",
       " 'began',\n",
       " 'an',\n",
       " 'initial',\n",
       " 'four',\n",
       " '-',\n",
       " 'year',\n",
       " 'project',\n",
       " 'of',\n",
       " 'digit',\n",
       " '##ising',\n",
       " 'its',\n",
       " 'collection',\n",
       " 'of',\n",
       " 'manuscripts',\n",
       " ',',\n",
       " 'to',\n",
       " 'be',\n",
       " 'made',\n",
       " 'available',\n",
       " 'online',\n",
       " '.',\n",
       " 'the',\n",
       " 'vatican',\n",
       " 'secret',\n",
       " 'archives',\n",
       " 'were',\n",
       " 'separated',\n",
       " 'from',\n",
       " 'the',\n",
       " 'library',\n",
       " 'at',\n",
       " 'the',\n",
       " 'beginning',\n",
       " 'of',\n",
       " 'the',\n",
       " '17th',\n",
       " 'century',\n",
       " ';',\n",
       " 'they',\n",
       " 'contain',\n",
       " 'another',\n",
       " '150',\n",
       " ',',\n",
       " '000',\n",
       " 'items',\n",
       " '.',\n",
       " 'scholars',\n",
       " 'have',\n",
       " 'traditionally',\n",
       " 'divided',\n",
       " 'the',\n",
       " 'history',\n",
       " 'of',\n",
       " 'the',\n",
       " 'library',\n",
       " 'into',\n",
       " 'five',\n",
       " 'periods',\n",
       " ',',\n",
       " 'pre',\n",
       " '-',\n",
       " 'later',\n",
       " '##an',\n",
       " ',',\n",
       " 'later',\n",
       " '##an',\n",
       " ',',\n",
       " 'av',\n",
       " '##ignon',\n",
       " ',',\n",
       " 'pre',\n",
       " '-',\n",
       " 'vatican',\n",
       " 'and',\n",
       " 'vatican',\n",
       " '.',\n",
       " 'the',\n",
       " 'pre',\n",
       " '-',\n",
       " 'later',\n",
       " '##an',\n",
       " 'period',\n",
       " ',',\n",
       " 'comprising',\n",
       " 'the',\n",
       " 'initial',\n",
       " 'days',\n",
       " 'of',\n",
       " 'the',\n",
       " 'library',\n",
       " ',',\n",
       " 'dated',\n",
       " 'from',\n",
       " 'the',\n",
       " 'earliest',\n",
       " 'days',\n",
       " 'of',\n",
       " 'the',\n",
       " 'church',\n",
       " '.',\n",
       " 'only',\n",
       " 'a',\n",
       " 'handful',\n",
       " 'of',\n",
       " 'volumes',\n",
       " 'survive',\n",
       " 'from',\n",
       " 'this',\n",
       " 'period',\n",
       " ',',\n",
       " 'though',\n",
       " 'some',\n",
       " 'are',\n",
       " 'very',\n",
       " 'significant',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1bdfd6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[-5.7596, -6.3596, -8.2319, -8.3115, -8.0051, -8.3296, -8.9699, -9.7291,\n",
       "         -5.7595, -5.7796, -5.2582, -6.8558, -6.5457, -8.7256, -7.9886, -8.1651,\n",
       "         -7.0398, -7.5649, -7.7064, -6.8116, -5.5825, -7.3712, -8.5052, -7.4897,\n",
       "         -7.4413, -5.5568, -7.9109, -8.3040, -6.9405, -7.2482, -5.9923, -8.4171,\n",
       "         -7.9642, -6.7963, -7.7127, -8.5719, -7.1798, -8.3095, -6.0287, -7.5948,\n",
       "         -7.8911, -5.8713, -6.8039, -7.8272, -5.7088, -7.4628, -8.3072, -7.1413,\n",
       "         -7.2169, -8.1456, -7.3387, -7.5709, -7.9867, -5.1420, -7.4005, -5.6409,\n",
       "         -7.5569, -5.1269, -6.1124, -6.6586, -8.0124, -8.2980, -6.5366, -8.2782,\n",
       "         -5.6247, -5.9623, -7.9793, -7.9810, -7.1552, -6.9052, -5.2528, -8.0694,\n",
       "         -5.2650, -5.5371, -7.6018, -5.8719, -7.0912, -5.7293, -8.1970, -7.8006,\n",
       "         -6.4828, -7.4003, -8.0931, -7.7046, -6.7348, -8.5266, -8.0527, -8.4268,\n",
       "         -8.6404, -6.6866, -8.5113, -7.8682, -8.2312, -6.8412, -7.1432, -8.7183,\n",
       "         -8.3360, -8.2110, -7.6824, -7.6413, -8.7823, -8.3865, -7.9204, -8.6433,\n",
       "         -8.3862, -8.2250, -5.7607, -5.7061, -7.3159, -7.7898, -6.7896, -5.2474,\n",
       "         -6.8607, -7.5131, -5.1702, -8.3739, -6.6233, -8.5753, -6.6095, -8.6389,\n",
       "         -7.2662, -8.4655, -5.4644, -8.0242, -6.0716, -6.1057, -7.7381, -8.3234,\n",
       "         -6.5785, -8.5344, -6.5646, -8.4646, -7.6770, -7.4497, -8.3504, -7.7065,\n",
       "         -8.6455, -6.7955, -7.3783, -7.3207, -5.9158, -8.4550, -7.4610, -8.5297,\n",
       "         -7.2531, -8.0253, -8.5917, -7.0044, -8.6025, -6.9176, -8.1140, -8.2621,\n",
       "         -8.0113, -8.8293, -8.1348, -7.6996, -8.2490, -7.4175, -6.9816, -7.0848,\n",
       "         -8.4004, -6.9890, -5.4039, -8.3646, -7.4678, -7.6577, -7.6380, -8.8529,\n",
       "         -7.4075, -7.2874, -8.4391, -7.8462, -8.1455, -7.9052, -7.7685, -7.1117,\n",
       "         -8.3419, -7.0254, -8.0732, -4.9427, -8.1561, -8.0585, -7.2416, -8.6953,\n",
       "         -5.7999, -8.6244, -7.6292, -8.3924, -7.4810, -7.7620, -6.0449, -8.3112,\n",
       "         -7.1068, -6.2729, -7.6742, -7.5265, -8.4215, -7.1633, -8.3270, -8.2958,\n",
       "         -7.9091, -8.2921, -8.2425, -7.8282, -8.6226, -8.4015, -8.0496, -8.6511,\n",
       "         -8.9043, -7.9768, -8.4026, -8.7018, -7.9902, -9.0821, -8.9455, -8.1337,\n",
       "         -5.7595,  3.4416,  0.3797,  2.4928,  1.2169,  0.7307, -0.7942, -4.4730,\n",
       "         -1.2300, -1.3628,  5.0076,  5.5668,  3.0195, -3.1832,  2.1674, -4.5696,\n",
       "         -3.3597, -4.4309, -4.1668, -2.3419, -5.5114, -5.4951, -3.6711, -5.9858,\n",
       "         -5.3758, -1.3977, -6.7931, -4.8941, -4.9333, -0.1118, -3.7773, -2.0026,\n",
       "         -1.7342, -6.3754, -4.4110, -5.2540, -3.7282, -7.4941, -5.3108, -6.4631,\n",
       "         -5.5758, -6.6614, -8.3493, -6.2621, -5.4659, -7.6357, -4.7362, -7.4314,\n",
       "         -6.7383, -5.6582, -7.2834, -8.4964, -8.2494, -6.1218, -6.8883, -5.7918,\n",
       "         -7.8539, -6.9735, -8.8705, -7.4965, -7.8554, -8.2774, -7.3756, -5.5809,\n",
       "         -9.0674, -8.4681, -7.5066, -8.7212, -8.3363, -7.8350, -9.2039, -5.7596]],\n",
       "       grad_fn=<CopyBackwards>), end_logits=tensor([[-2.5119, -6.2548, -7.1609, -7.9624, -7.2006, -8.0974, -7.7395, -7.9401,\n",
       "         -2.5119, -6.8608, -5.9537, -5.0153, -4.0525, -6.9770, -5.9663, -5.5472,\n",
       "         -7.6490, -6.7318, -7.0168, -7.2373, -6.0095, -4.8470, -6.9327, -7.2753,\n",
       "         -7.3145, -6.6789, -4.4923, -4.8660, -7.0607, -7.3692, -5.3790, -7.3975,\n",
       "         -7.2750, -6.3259, -4.5474, -5.5462, -7.0676, -7.4761, -6.2521, -4.6492,\n",
       "         -5.8906, -7.0919, -6.3017, -7.4151, -5.8882, -4.5139, -5.3195, -7.7556,\n",
       "         -7.5818, -7.8089, -7.6715, -5.8112, -6.0707, -7.2316, -7.4068, -7.3449,\n",
       "         -7.4881, -6.3962, -5.2923, -5.1583, -7.5064, -7.6937, -3.6080, -6.7995,\n",
       "         -7.5389, -7.4153, -7.6406, -7.8946, -7.4489, -6.7854, -5.7509, -7.6817,\n",
       "         -5.6339, -3.1484, -4.3539, -7.3316, -7.6054, -7.3628, -7.3938, -6.7066,\n",
       "         -6.9480, -4.4110, -7.2899, -7.2213, -4.4303, -5.3877, -7.8664, -7.2303,\n",
       "         -7.4737, -7.6087, -7.7737, -7.5853, -6.7829, -6.3479, -4.7287, -5.5721,\n",
       "         -7.4665, -7.7108, -8.0449, -7.6753, -7.5012, -7.0296, -7.6910, -7.2636,\n",
       "         -5.6921, -4.9163, -7.7911, -7.2462, -6.2114, -7.7331, -7.8220, -6.0756,\n",
       "         -5.5326, -7.4791, -5.6108, -7.0844, -6.2989, -6.9841, -5.9159, -6.9163,\n",
       "         -6.2167, -7.6568, -3.2521, -4.3340, -7.9529, -7.4690, -6.5497, -7.9314,\n",
       "         -7.2030, -7.7458, -5.9236, -7.3603, -7.4581, -6.6587, -7.2886, -5.7989,\n",
       "         -8.0330, -6.3927, -4.4657, -3.9438, -7.2587, -7.8042, -6.3502, -8.1061,\n",
       "         -7.2260, -6.5294, -8.2114, -6.6365, -8.3463, -6.8841, -7.6283, -8.2079,\n",
       "         -7.1030, -8.2205, -6.5283, -7.9820, -8.1157, -7.0491, -8.2331, -6.8097,\n",
       "         -7.8881, -8.3206, -3.1612, -4.2588, -8.2123, -8.0139, -6.8195, -7.0161,\n",
       "         -8.1532, -7.9085, -7.1279, -7.8703, -7.9398, -7.8774, -7.7984, -6.9879,\n",
       "         -7.3624, -6.5668, -8.0368, -6.0626, -5.7138, -7.8820, -6.5248, -7.8963,\n",
       "         -4.0734, -5.8346, -7.7230, -7.8866, -7.8900, -7.3907, -4.2960, -4.3411,\n",
       "         -7.7112, -7.2543, -6.9236, -4.9963, -7.1846, -6.8701, -7.2874, -7.7876,\n",
       "         -5.9155, -7.6616, -7.7350, -7.4816, -7.6691, -7.7915, -6.8808, -5.7532,\n",
       "         -5.9424, -7.4265, -7.9092, -7.9634, -7.9062, -7.8745, -7.3874, -5.9442,\n",
       "         -2.5117, -3.7866, -4.1482, -1.1562, -2.0069, -5.0492, -2.5706, -5.4821,\n",
       "         -5.5296, -3.0817, -1.2411,  2.3263,  7.0180,  2.1083, -2.8815, -4.6968,\n",
       "         -5.4717,  0.1717,  0.2077, -5.4978, -0.8199, -0.1498, -5.4081, -0.9196,\n",
       "         -0.5911, -4.1795, -6.4838, -0.7342, -3.4267,  5.2164,  3.9999, -6.0087,\n",
       "         -4.6457, -6.1146, -5.8299, -1.9770, -0.1670, -4.7139, -6.5166, -7.4642,\n",
       "         -5.0294, -4.3687, -7.1921, -6.4135, -2.4392, -4.8040, -6.0449, -7.4582,\n",
       "         -7.7023, -5.7783, -5.8975, -7.4654, -7.3532, -3.3300, -4.3212, -7.2681,\n",
       "         -7.8981, -5.9333, -7.4205, -5.7711, -6.2775, -8.0168, -7.5062, -3.6342,\n",
       "         -6.1111, -8.2517, -7.5478, -7.9123, -8.3544, -5.6409, -5.9354, -2.5119]],\n",
       "       grad_fn=<CopyBackwards>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(inputs[\"input_ids\"],  token_type_ids=inputs[\"token_type_ids\"])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "11186224",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_start = torch.argmax(output.start_logits)\n",
    "answer_end = torch.argmax(output.end_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "92c2e051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(227)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f75428f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(228)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f52302f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'five periods'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = \"I am unable to find the answer to this question. Can you please ask another question?\"\n",
    "if answer_end >= answer_start:\n",
    "    answer = \" \".join(tokens[answer_start:answer_end+1])\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "aed359ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \" ##\" in answer:\n",
    "    answer = answer.replace(\" ##\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "7078f324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'five periods'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4dd64d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'into periods'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a631c7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aba164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
